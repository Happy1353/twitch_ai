"""
AI Brain module - handles ChatGPT integration
"""
import asyncio
from openai import AsyncOpenAI
import config
from typing import List, Dict


class AIBrain:
    """Handles AI responses using OpenAI ChatGPT"""
    
    def __init__(self):
        """Initialize AI brain"""
        # Use Groq API (OpenAI-compatible, FREE!)
        self.client = AsyncOpenAI(
            api_key=config.OPENAI_API_KEY,  # Will use Groq key
            base_url="https://api.groq.com/openai/v1"
        )
        self.conversation_history: List[Dict[str, str]] = []
        self.max_history = 10  # Keep last 10 messages for context
        
        # Initialize with character personality
        self.system_prompt = f"""–¢—ã {config.CHARACTER_NAME} - –≤–∏—Ä—Ç—É–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∏–º–µ—Ä—à–∞ –Ω–∞ Twitch.
{config.CHARACTER_PERSONALITY}

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –ö–†–ê–¢–ö–û (–º–∞–∫—Å–∏–º—É–º 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ —É–º–µ—Ä–µ–Ω–Ω–æ 
3. –ë—É–¥—å –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –∏ –∂–∏–≤–æ–π
4. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ
5. –ú–æ–∂–µ—à—å –±—ã—Ç—å –∏–≥—Ä–∏–≤–æ–π –∏ –∫–æ–∫–µ—Ç–ª–∏–≤–æ–π
6. –ò–Ω–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–Ω–≥ –∏ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –≤—ã—Ä–∞–∂–µ–Ω–∏—è
7. –ü–æ–º–Ω–∏, —á—Ç–æ —Ç—ã –æ–±—â–∞–µ—à—å—Å—è —Å–æ –∑—Ä–∏—Ç–µ–ª—è–º–∏ –≤ —á–∞—Ç–µ
"""
        
        self.conversation_history.append({
            "role": "system",
            "content": self.system_prompt
        })
        
    async def get_response(self, username: str, message: str) -> str:
        """
        Get AI response for a message
        
        Args:
            username: Username who sent the message
            message: Message content
            
        Returns:
            AI generated response
        """
        try:
            # Add user message to history
            user_message = f"{username} —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {message}"
            self.conversation_history.append({
                "role": "user",
                "content": user_message
            })
            
            # Get response from Groq (FREE!)
            response = await self.client.chat.completions.create(
                model="llama-3.3-70b-versatile",  # NEW Groq model (updated Oct 2024)
                messages=self.conversation_history[-self.max_history:],  # Use recent history
                max_tokens=150,
                temperature=0.9,  # More creative responses
            )
            
            ai_response = response.choices[0].message.content.strip()
            
            # Limit response length
            if len(ai_response) > config.MAX_RESPONSE_LENGTH:
                ai_response = ai_response[:config.MAX_RESPONSE_LENGTH] + "..."
            
            # Add AI response to history
            self.conversation_history.append({
                "role": "assistant",
                "content": ai_response
            })
            
            # Trim history if too long
            if len(self.conversation_history) > self.max_history + 1:  # +1 for system prompt
                self.conversation_history = [self.conversation_history[0]] + self.conversation_history[-(self.max_history):]
            
            return ai_response
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ AI: {e}")
            return "–û–π, —á—Ç–æ-—Ç–æ –ø–æ—à–ª–æ –Ω–µ —Ç–∞–∫... üòÖ"
    
    def reset_conversation(self):
        """Reset conversation history"""
        self.conversation_history = [self.conversation_history[0]]  # Keep system prompt

